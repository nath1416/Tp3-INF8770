{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863aa969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2432a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"Dataset_TP3\")\n",
    "videos_paths = [p for p in path.iterdir() if p.is_file()]\n",
    "\n",
    "videos: dict[Path, cv2.VideoCapture] = {}\n",
    "for file in videos_paths:\n",
    "    vid = cv2.VideoCapture(file)\n",
    "    if not vid.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        continue\n",
    "    videos[file] = vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d98d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive = False\n",
    "r = 50\n",
    "edge_threshold = 30\n",
    "\n",
    "edges = {}\n",
    "\n",
    "print(f\"Processing {len(videos)} videos\")\n",
    "for video_path, video in videos.items():\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "    edge_maps = np.zeros((frame_count, h, w), dtype=np.uint8)\n",
    "    histograms = np.zeros((frame_count, r), dtype=np.float32)\n",
    "\n",
    "    center_y, center_x = h // 2, w // 2\n",
    "    y, x = np.ogrid[:h, :w]\n",
    "    distances = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)\n",
    "    bin_size = np.max(distances) / r\n",
    "\n",
    "    bin_indices = np.clip((distances / bin_size).astype(np.int32), 0, r - 1)\n",
    "\n",
    "    for frame_idx in tqdm(range(frame_count)):\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            print(f\"Error: Could not read frame {frame_idx}.\")\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        sobel_x = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)\n",
    "        sobel_y = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)\n",
    "\n",
    "        magnitude = cv2.magnitude(sobel_x, sobel_y)\n",
    "        edge_maps[frame_idx] = (magnitude > edge_threshold).astype(np.uint8)\n",
    "\n",
    "        for i in range(r):\n",
    "            mask = bin_indices == i\n",
    "            if np.any(mask):\n",
    "                histograms[frame_idx, i] = np.mean(magnitude[mask])\n",
    "\n",
    "        if interactive:\n",
    "            display = cv2.convertScaleAbs(magnitude)\n",
    "            cv2.imshow(\"Edges\", display)\n",
    "            if cv2.waitKey(int(1000 / fps)) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    edges[video_path] = {\"edge_maps\": edge_maps, \"histograms\": histograms}\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a92b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate_edges(edge_map, kernel_size=3):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    return cv2.dilate(edge_map, kernel)\n",
    "\n",
    "\n",
    "for video_name, video_data in edges.items():\n",
    "    edge_maps = video_data[\"edge_maps\"]\n",
    "    frame_count = edge_maps.shape[0]\n",
    "\n",
    "    print(f\"Processing {frame_count} frames for video {video_name.name}\")\n",
    "\n",
    "    rho_in_list = []\n",
    "    rho_out_list = []\n",
    "\n",
    "    for t in tqdm(range(frame_count - 1)):\n",
    "        E_t = edge_maps[t]\n",
    "        E_t1 = edge_maps[t + 1]\n",
    "\n",
    "        D_t = dilate_edges(E_t)\n",
    "        D_t1 = dilate_edges(E_t1)\n",
    "\n",
    "        sum_E_t1 = np.sum(E_t1)\n",
    "        if sum_E_t1 > 0:\n",
    "            rho_in = 1 - np.sum(D_t & E_t1) / sum_E_t1\n",
    "        else:\n",
    "            rho_in = 0\n",
    "\n",
    "        sum_E_t = np.sum(E_t)\n",
    "        if sum_E_t > 0:\n",
    "            rho_out = 1 - np.sum(E_t & D_t1) / sum_E_t\n",
    "        else:\n",
    "            rho_out = 0\n",
    "\n",
    "        rho_in_list.append(rho_in)\n",
    "        rho_out_list.append(rho_out)\n",
    "\n",
    "    print(f\"Video: {video_name.name}\")\n",
    "    print(\n",
    "        f\"Mean ρin: {np.mean(rho_in_list):.4f}, Mean ρout: {np.mean(rho_out_list):.4f}\"\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(rho_in_list, label=\"ρin (entering edges)\")\n",
    "    plt.plot(rho_out_list, label=\"ρout (exiting edges)\")\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.ylabel(\"ρ\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Edge Change Metrics - {video_name.name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb72fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_transitions(\n",
    "    rho_in_list, rho_out_list, cut_threshold=0.7, gradual_threshold=0.3, min_duration=5\n",
    "):\n",
    "    rho_in = np.array(rho_in_list)\n",
    "    rho_out = np.array(rho_out_list)\n",
    "    rho_max = np.maximum(rho_in, rho_out)\n",
    "\n",
    "    cuts = []\n",
    "    fades = []\n",
    "    gradations = []\n",
    "\n",
    "    for t in range(len(rho_max)):\n",
    "        if rho_max[t] > cut_threshold:\n",
    "            is_isolated = True\n",
    "            if t > 0 and rho_max[t - 1] > gradual_threshold:\n",
    "                is_isolated = False\n",
    "            if t < len(rho_max) - 1 and rho_max[t + 1] > gradual_threshold:\n",
    "                is_isolated = False\n",
    "            if is_isolated:\n",
    "                cuts.append(t)\n",
    "\n",
    "    in_transition = False\n",
    "    transition_start = 0\n",
    "\n",
    "    for t in range(len(rho_max)):\n",
    "        if not in_transition and rho_max[t] > gradual_threshold:\n",
    "            in_transition = True\n",
    "            transition_start = t\n",
    "        elif in_transition and rho_max[t] <= gradual_threshold:\n",
    "            in_transition = False\n",
    "            duration = t - transition_start\n",
    "\n",
    "            if duration >= min_duration:\n",
    "                segment_in = rho_in[transition_start:t]\n",
    "                segment_out = rho_out[transition_start:t]\n",
    "\n",
    "                first_half = len(segment_in) // 2\n",
    "                in_dominant_start = np.mean(segment_in[:first_half]) > np.mean(\n",
    "                    segment_out[:first_half]\n",
    "                )\n",
    "                out_dominant_end = np.mean(segment_out[first_half:]) > np.mean(\n",
    "                    segment_in[first_half:]\n",
    "                )\n",
    "\n",
    "                if in_dominant_start and out_dominant_end:\n",
    "                    fades.append((transition_start, t))\n",
    "                else:\n",
    "                    gradations.append((transition_start, t))\n",
    "\n",
    "    if in_transition and (len(rho_max) - transition_start) >= min_duration:\n",
    "        t = len(rho_max)\n",
    "        segment_in = rho_in[transition_start:t]\n",
    "        segment_out = rho_out[transition_start:t]\n",
    "        first_half = len(segment_in) // 2\n",
    "        in_dominant_start = np.mean(segment_in[:first_half]) > np.mean(\n",
    "            segment_out[:first_half]\n",
    "        )\n",
    "        out_dominant_end = np.mean(segment_out[first_half:]) > np.mean(\n",
    "            segment_in[first_half:]\n",
    "        )\n",
    "\n",
    "        if in_dominant_start and out_dominant_end:\n",
    "            fades.append((transition_start, t))\n",
    "        else:\n",
    "            gradations.append((transition_start, t))\n",
    "\n",
    "    return cuts, fades, gradations\n",
    "\n",
    "\n",
    "for video_name, video_data in edges.items():\n",
    "    edge_maps = video_data[\"edge_maps\"]\n",
    "    frame_count = edge_maps.shape[0]\n",
    "\n",
    "    rho_in_list = []\n",
    "    rho_out_list = []\n",
    "\n",
    "    for t in range(frame_count - 1):\n",
    "        E_t = edge_maps[t]\n",
    "        E_t1 = edge_maps[t + 1]\n",
    "        D_t = dilate_edges(E_t)\n",
    "        D_t1 = dilate_edges(E_t1)\n",
    "\n",
    "        sum_E_t1 = np.sum(E_t1)\n",
    "        rho_in = 1 - np.sum(D_t & E_t1) / sum_E_t1 if sum_E_t1 > 0 else 0\n",
    "\n",
    "        sum_E_t = np.sum(E_t)\n",
    "        rho_out = 1 - np.sum(E_t & D_t1) / sum_E_t if sum_E_t > 0 else 0\n",
    "\n",
    "        rho_in_list.append(rho_in)\n",
    "        rho_out_list.append(rho_out)\n",
    "\n",
    "    cuts, fades, gradations = detect_transitions(rho_in_list, rho_out_list)\n",
    "\n",
    "    print(f\"\\n=== {video_name.name} ===\")\n",
    "    print(f\"Cuts detected: {len(cuts)} at frames {cuts}\")\n",
    "    print(f\"Fades detected: {len(fades)} - {fades}\")\n",
    "    print(f\"Gradations detected: {len(gradations)} - {gradations}\")\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    rho_max = np.maximum(rho_in_list, rho_out_list)\n",
    "\n",
    "    plt.plot(rho_in_list, label=\"ρin (entering edges)\", alpha=0.7)\n",
    "    plt.plot(rho_out_list, label=\"ρout (exiting edges)\", alpha=0.7)\n",
    "    plt.plot(rho_max, label=\"ρmax\", color=\"black\", linewidth=1.5)\n",
    "\n",
    "    for c in cuts:\n",
    "        plt.axvline(\n",
    "            x=c,\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=2,\n",
    "            label=\"Cut\" if c == cuts[0] else \"\",\n",
    "        )\n",
    "\n",
    "    for i, (start, end) in enumerate(fades):\n",
    "        plt.axvspan(start, end, alpha=0.3, color=\"blue\", label=\"Fade\" if i == 0 else \"\")\n",
    "\n",
    "    for i, (start, end) in enumerate(gradations):\n",
    "        plt.axvspan(\n",
    "            start, end, alpha=0.3, color=\"green\", label=\"Gradation\" if i == 0 else \"\"\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.ylabel(\"ρ\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Scene Transition Detection - {video_name.name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7e7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTION_THRESHOLD = 1\n",
    "cuts_path = Path(\"./cuts\")\n",
    "\n",
    "detected_cuts = {}\n",
    "\n",
    "for video_name, video_data in edges.items():\n",
    "    edge_maps = video_data[\"edge_maps\"]\n",
    "    frame_count = edge_maps.shape[0]\n",
    "\n",
    "    rho_in_list = []\n",
    "    rho_out_list = []\n",
    "\n",
    "    for t in range(frame_count - 1):\n",
    "        E_t = edge_maps[t]\n",
    "        E_t1 = edge_maps[t + 1]\n",
    "        D_t = dilate_edges(E_t)\n",
    "        D_t1 = dilate_edges(E_t1)\n",
    "\n",
    "        sum_E_t1 = np.sum(E_t1)\n",
    "        rho_in = 1 - np.sum(D_t & E_t1) / sum_E_t1 if sum_E_t1 > 0 else 0\n",
    "\n",
    "        sum_E_t = np.sum(E_t)\n",
    "        rho_out = 1 - np.sum(E_t & D_t1) / sum_E_t if sum_E_t > 0 else 0\n",
    "\n",
    "        rho_in_list.append(rho_in)\n",
    "        rho_out_list.append(rho_out)\n",
    "\n",
    "    cuts, fades, gradations = detect_transitions(rho_in_list, rho_out_list)\n",
    "    detected_cuts[video_name] = cuts\n",
    "\n",
    "for video_name, gen_cuts in detected_cuts.items():\n",
    "    name_file = video_name.name.split(\".\")[0]\n",
    "    valid_cuts_path = cuts_path / f\"{name_file}.txt\"\n",
    "\n",
    "    if not valid_cuts_path.exists():\n",
    "        print(f\"Ground truth file not found: {valid_cuts_path}\")\n",
    "        continue\n",
    "\n",
    "    with open(valid_cuts_path, \"r\") as f:\n",
    "        valid_cuts_str = f.read()\n",
    "\n",
    "    valid_cuts = []\n",
    "    for x in valid_cuts_str.split(\",\"):\n",
    "        stripped = x.strip()\n",
    "        if stripped.isdigit():\n",
    "            valid_cuts.append(int(stripped))\n",
    "\n",
    "    correct_cuts = []\n",
    "    incorrect_cuts = []\n",
    "\n",
    "    for gc in gen_cuts:\n",
    "        found = False\n",
    "        for vc in valid_cuts:\n",
    "            if abs(gc - vc) <= DETECTION_THRESHOLD:\n",
    "                found = True\n",
    "                break\n",
    "        if found:\n",
    "            correct_cuts.append(gc)\n",
    "        else:\n",
    "            incorrect_cuts.append(gc)\n",
    "\n",
    "    TP = len(correct_cuts)\n",
    "    FP = len(incorrect_cuts)\n",
    "\n",
    "    missed_cuts = []\n",
    "    for vc in valid_cuts:\n",
    "        detected = any(abs(gc - vc) <= DETECTION_THRESHOLD for gc in gen_cuts)\n",
    "        if not detected:\n",
    "            missed_cuts.append(vc)\n",
    "    FN = len(missed_cuts)\n",
    "\n",
    "    precision = TP / (TP + FP) * 100 if (TP + FP) > 0 else 0.0\n",
    "\n",
    "    recall = TP / (TP + FN) * 100 if (TP + FN) > 0 else 0.0\n",
    "\n",
    "    if precision + recall > 0:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1_score = 0.0\n",
    "\n",
    "    total_detected = len(gen_cuts)\n",
    "\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"Vidéo: {video_name.name}\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    print(f\"Cuts détectés: {total_detected} | Ground truth: {len(valid_cuts)}\")\n",
    "    print(f\"\\n✓ Détections correctes (TP): {TP}\")\n",
    "    print(f\"  Frames: {correct_cuts}\")\n",
    "    print(f\"\\n✗ Faux positifs (FP): {FP}\")\n",
    "    print(f\"  Frames: {incorrect_cuts}\")\n",
    "    print(f\"\\n⊘ Cuts manqués (FN): {FN}\")\n",
    "    print(f\"  Frames: {missed_cuts}\")\n",
    "    print(f\"\\n{'─' * 50}\")\n",
    "    print(f\"Métriques:\")\n",
    "    print(f\"   Précision: {precision:.1f}%\")\n",
    "    print(f\"   Rappel:    {recall:.1f}%\")\n",
    "    print(f\"   F1 Score:  {f1_score:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74f7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
